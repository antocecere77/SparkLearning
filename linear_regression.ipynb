{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressione Lineare con Spark MLlib\n",
    "\n",
    "### In questo notebook vedremo come eseguire una semplice regressione, utilizzando un modello di Regressione Lineare, con il modulo MLlib di Spark. Il modello che andremo a creare avrà lo scopo di stimare il valore di un'abitazione utilizzando un set di proprietà:\n",
    "\n",
    "### CRIM Tasso di criminalità per capita\n",
    "### ZN Percentuale di terreni residenziali suddivisi in zone per lotti superiori a 25.000 sq.ft.\n",
    "### INDUS Percentuale di ettari di attività non al dettaglio per città.\n",
    "### CHAS Variabile dummy che indica la prossimità al fiume Charles.\n",
    "### NOX Concentrazione di ossido d'azoto (parti per 10 milioni).\n",
    "### RM Numero medio di stanze per abitazione\n",
    "### AGE Percentuale di abitazione occupate costruite dopo il 1940\n",
    "### DIS Media pesata delle distanze da 5 centri lavorativi di Boston.\n",
    "### RAD Indice di accessibilità ad autostrade\n",
    "### TAX Aliquota dell'imposta sulla proprietà a valore pieno in 10.000 USD.\n",
    "### PRATIO Rapporto studente-insegnante per città.\n",
    "### BLACK 1000(Bk - 0.63)^2 dove Bk è la percentuale di abitanti di colore per città\n",
    "### LSTAT Percentuale della popolazione povera\n",
    "### MEDV Mediana del valore di abitazioni occupate in 1.000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "| ID|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+---+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|  1|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|  2|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|  4|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|  5|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "|  7|0.08829|12.5| 7.87|   0|0.524|6.012|66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
      "+---+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df = spark.read.csv(\"./data/houses_train.csv\", inferSchema=True, header=True)\n",
    "housing_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n"
     ]
    }
   ],
   "source": [
    "features_cols = housing_df.columns[1:-1]\n",
    "print(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "| ID|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|            features|\n",
      "+---+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|  1|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632,18.0,2.3...|\n",
      "|  2|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[0.02731,0.0,7.07...|\n",
      "|  4|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[0.03237,0.0,2.18...|\n",
      "|  5|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[0.06905,0.0,2.18...|\n",
      "|  7|0.08829|12.5| 7.87|   0|0.524|6.012|66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|[0.08829,12.5,7.8...|\n",
      "+---+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features_cols, outputCol=\"features\")\n",
    "data_df = assembler.transform(housing_df)\n",
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
