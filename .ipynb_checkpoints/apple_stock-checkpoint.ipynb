{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi del prezzo delle azioni di Apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inizializziamo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AppleStock\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importiamo il Dataset all'interno di un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|               Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|1980-12-12 00:00:00|0.513393|0.515625|0.513393|0.513393| 0.410525|117258400|\n",
      "|1980-12-15 00:00:00|0.488839|0.488839|0.486607|0.486607| 0.389106| 43971200|\n",
      "|1980-12-16 00:00:00|0.453125|0.453125|0.450893|0.450893| 0.360548| 26432000|\n",
      "|1980-12-17 00:00:00|0.462054|0.464286|0.462054|0.462054| 0.369472| 21610400|\n",
      "|1980-12-18 00:00:00|0.475446|0.477679|0.475446|0.475446| 0.380182| 18362400|\n",
      "|1980-12-19 00:00:00|0.504464|0.506696|0.504464|0.504464| 0.403385| 12157600|\n",
      "|1980-12-22 00:00:00|0.529018|0.531250|0.529018|0.529018| 0.423019|  9340800|\n",
      "|1980-12-23 00:00:00|0.551339|0.553571|0.551339|0.551339| 0.440868| 11737600|\n",
      "|1980-12-24 00:00:00|0.580357|0.582589|0.580357|0.580357| 0.464072| 12000800|\n",
      "|1980-12-26 00:00:00|0.633929|0.636161|0.633929|0.633929| 0.506909| 13893600|\n",
      "|1980-12-29 00:00:00|0.642857|0.645089|0.642857|0.642857| 0.514049| 23290400|\n",
      "|1980-12-30 00:00:00|0.629464|0.629464|0.627232|0.627232| 0.501554| 17220000|\n",
      "|1980-12-31 00:00:00|0.611607|0.611607|0.609375|0.609375| 0.487276|  8937600|\n",
      "|1981-01-02 00:00:00|0.616071|0.620536|0.616071|0.616071| 0.492630|  5415200|\n",
      "|1981-01-05 00:00:00|0.604911|0.604911|0.602679|0.602679| 0.481921|  8932000|\n",
      "|1981-01-06 00:00:00|0.578125|0.578125|0.575893|0.575893| 0.460502| 11289600|\n",
      "|1981-01-07 00:00:00|0.553571|0.553571|0.551339|0.551339| 0.440868| 13921600|\n",
      "|1981-01-08 00:00:00|0.542411|0.542411|0.540179|0.540179| 0.431944|  9956800|\n",
      "|1981-01-09 00:00:00|0.569196|0.571429|0.569196|0.569196| 0.455147|  5376000|\n",
      "|1981-01-12 00:00:00|0.569196|0.569196|0.564732|0.564732| 0.451577|  5924800|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/AAPL.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correggiamo lo schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|               Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|1980-12-12 00:00:00|0.513393|0.515625|0.513393|0.513393| 0.410525|117258400|\n",
      "|1980-12-15 00:00:00|0.488839|0.488839|0.486607|0.486607| 0.389106| 43971200|\n",
      "|1980-12-16 00:00:00|0.453125|0.453125|0.450893|0.450893| 0.360548| 26432000|\n",
      "|1980-12-17 00:00:00|0.462054|0.464286|0.462054|0.462054| 0.369472| 21610400|\n",
      "|1980-12-18 00:00:00|0.475446|0.477679|0.475446|0.475446| 0.380182| 18362400|\n",
      "|1980-12-19 00:00:00|0.504464|0.506696|0.504464|0.504464| 0.403385| 12157600|\n",
      "|1980-12-22 00:00:00|0.529018| 0.53125|0.529018|0.529018| 0.423019|  9340800|\n",
      "|1980-12-23 00:00:00|0.551339|0.553571|0.551339|0.551339| 0.440868| 11737600|\n",
      "|1980-12-24 00:00:00|0.580357|0.582589|0.580357|0.580357| 0.464072| 12000800|\n",
      "|1980-12-26 00:00:00|0.633929|0.636161|0.633929|0.633929| 0.506909| 13893600|\n",
      "|1980-12-29 00:00:00|0.642857|0.645089|0.642857|0.642857| 0.514049| 23290400|\n",
      "|1980-12-30 00:00:00|0.629464|0.629464|0.627232|0.627232| 0.501554| 17220000|\n",
      "|1980-12-31 00:00:00|0.611607|0.611607|0.609375|0.609375| 0.487276|  8937600|\n",
      "|1981-01-02 00:00:00|0.616071|0.620536|0.616071|0.616071|  0.49263|  5415200|\n",
      "|1981-01-05 00:00:00|0.604911|0.604911|0.602679|0.602679| 0.481921|  8932000|\n",
      "|1981-01-06 00:00:00|0.578125|0.578125|0.575893|0.575893| 0.460502| 11289600|\n",
      "|1981-01-07 00:00:00|0.553571|0.553571|0.551339|0.551339| 0.440868| 13921600|\n",
      "|1981-01-08 00:00:00|0.542411|0.542411|0.540179|0.540179| 0.431944|  9956800|\n",
      "|1981-01-09 00:00:00|0.569196|0.571429|0.569196|0.569196| 0.455147|  5376000|\n",
      "|1981-01-12 00:00:00|0.569196|0.569196|0.564732|0.564732| 0.451577|  5924800|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data_schema = [ StructField('Date', TimestampType(), True),\n",
    "                StructField('Open', FloatType(), True),\n",
    "                StructField('High', FloatType(), True),\n",
    "                StructField('Low', FloatType(), True),\n",
    "                StructField('Close', FloatType(), True),\n",
    "                StructField('Adj Close', FloatType(), True),\n",
    "                StructField('Volume', IntegerType(), True),]\n",
    "            \n",
    "schema = StructType(fields=data_schema)\n",
    "\n",
    "df = spark.read.schema(schema).option(\"header\",\"true\").option(\"inferSchema\",\"false\") \\\n",
    "                    .csv(\"data/AAPL.csv\")\n",
    "\n",
    "df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertiamo il timestamp in una data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|      Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|1980-12-12|0.513393|0.515625|0.513393|0.513393| 0.410525|117258400|\n",
      "|1980-12-15|0.488839|0.488839|0.486607|0.486607| 0.389106| 43971200|\n",
      "|1980-12-16|0.453125|0.453125|0.450893|0.450893| 0.360548| 26432000|\n",
      "|1980-12-17|0.462054|0.464286|0.462054|0.462054| 0.369472| 21610400|\n",
      "|1980-12-18|0.475446|0.477679|0.475446|0.475446| 0.380182| 18362400|\n",
      "|1980-12-19|0.504464|0.506696|0.504464|0.504464| 0.403385| 12157600|\n",
      "|1980-12-22|0.529018| 0.53125|0.529018|0.529018| 0.423019|  9340800|\n",
      "|1980-12-23|0.551339|0.553571|0.551339|0.551339| 0.440868| 11737600|\n",
      "|1980-12-24|0.580357|0.582589|0.580357|0.580357| 0.464072| 12000800|\n",
      "|1980-12-26|0.633929|0.636161|0.633929|0.633929| 0.506909| 13893600|\n",
      "|1980-12-29|0.642857|0.645089|0.642857|0.642857| 0.514049| 23290400|\n",
      "|1980-12-30|0.629464|0.629464|0.627232|0.627232| 0.501554| 17220000|\n",
      "|1980-12-31|0.611607|0.611607|0.609375|0.609375| 0.487276|  8937600|\n",
      "|1981-01-02|0.616071|0.620536|0.616071|0.616071|  0.49263|  5415200|\n",
      "|1981-01-05|0.604911|0.604911|0.602679|0.602679| 0.481921|  8932000|\n",
      "|1981-01-06|0.578125|0.578125|0.575893|0.575893| 0.460502| 11289600|\n",
      "|1981-01-07|0.553571|0.553571|0.551339|0.551339| 0.440868| 13921600|\n",
      "|1981-01-08|0.542411|0.542411|0.540179|0.540179| 0.431944|  9956800|\n",
      "|1981-01-09|0.569196|0.571429|0.569196|0.569196| 0.455147|  5376000|\n",
      "|1981-01-12|0.569196|0.569196|0.564732|0.564732| 0.451577|  5924800|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df = df.withColumn('Date', to_date(df[\"Date\"], \"yyyy-MM-dd\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è stato il valore massimo raggiunto dal AAPL? In che data lo ha raggiunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+---------+--------+\n",
      "|      Date|  Open|  High|   Low| Close|Adj Close|  Volume|\n",
      "+----------+------+------+------+------+---------+--------+\n",
      "|2018-10-03|230.05|233.47|229.78|232.07|229.39209|28654800|\n",
      "|2018-10-04|230.78|232.35|226.73|227.99|225.35918|32042000|\n",
      "|2018-10-02|227.25| 230.0|226.63|229.28| 226.6343|24788200|\n",
      "|2018-09-05|228.99|229.67| 225.1|226.87|224.25209|33333000|\n",
      "|2018-10-01|227.95|229.42|226.35|227.26| 224.6376|23600800|\n",
      "|2018-09-04|228.41|229.18|226.63|228.36| 225.7249|27390100|\n",
      "|2018-08-31|226.51|228.87| 226.0|227.63|225.00334|43340100|\n",
      "|2018-10-05|227.96|228.41|220.58|224.29|221.70186|33580500|\n",
      "|2018-09-13|223.52|228.35|222.57|226.41|223.79741|41706400|\n",
      "|2018-08-30|223.25|228.26| 222.4|225.03|222.43332|48793800|\n",
      "+----------+------+------+------+------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"High\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è stato il valore massimo raggiunto dal AAPL dopo il 2000? In che data lo ha raggiunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|      Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|2003-04-17|0.942857|0.946429|0.908571|0.937143| 0.820964|154064400|\n",
      "|2003-04-16|0.927857|0.976429|0.922857|0.945714| 0.828473|254044000|\n",
      "|2003-04-11|1.003571|1.031429|0.923571|0.942857|  0.82597|348177200|\n",
      "|2003-04-21|0.937857|0.942143|0.927143|0.938571| 0.822216| 38080000|\n",
      "|2003-04-24|0.965714|0.972143|0.928571|    0.96| 0.840988| 81277000|\n",
      "|2003-04-22|0.941429|0.972857|   0.935|   0.965| 0.845368| 75142200|\n",
      "|2003-04-25|0.961429|    0.97|   0.945|0.953571| 0.835356| 51329600|\n",
      "|2003-04-15|0.970714|0.971429|    0.95|0.956429| 0.837859| 75992000|\n",
      "|2002-10-08|0.992857|0.997143|0.954286|0.977143| 0.856006|113411200|\n",
      "|2003-04-23|0.966429|0.973571|0.954286|    0.97| 0.849748| 52420200|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Date >= '2000-01-01'\").orderBy(\"Low\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è la percentuale di giorni in cui il prezzo di chiusura è stato inferiore ai 100 USD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.67"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.filter(\"Close < 100\").count()/df.count()*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è la percentuale di giorni in cui il prezzo di chiusura è stato inferiore ai 100 USD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2014 = df.filter(\"Date >= '2014-01-01'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.54"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df2014.filter(\"Close < 100\").count()/df2014.count()*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizza il valore massimo per anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "dfGroupYear = df.groupBy(year(\"Date\").alias(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|year|max(High)|\n",
      "+----+---------+\n",
      "|2018|   233.47|\n",
      "|2017|    177.2|\n",
      "|2016|   118.69|\n",
      "|2015|   134.54|\n",
      "|2014|   119.75|\n",
      "|2013| 82.16286|\n",
      "|2012|100.72429|\n",
      "|2011| 60.95714|\n",
      "|2010|46.665714|\n",
      "|2009|30.564285|\n",
      "|2008|28.608572|\n",
      "|2007|28.994286|\n",
      "|2006|13.308572|\n",
      "|2005|    10.78|\n",
      "|2004| 4.969285|\n",
      "|2003| 1.786429|\n",
      "|2002| 1.869286|\n",
      "|2001| 1.937143|\n",
      "|2000| 5.370536|\n",
      "|1999| 4.214286|\n",
      "|1998|   1.5625|\n",
      "|1997| 1.055804|\n",
      "|1996| 1.267857|\n",
      "|1995| 1.790179|\n",
      "|1994|   1.5625|\n",
      "|1993| 2.330357|\n",
      "|1992|      2.5|\n",
      "|1991| 2.616071|\n",
      "|1990| 1.705357|\n",
      "|1989| 1.799107|\n",
      "|1988| 1.705357|\n",
      "|1987| 2.133929|\n",
      "|1986| 0.783482|\n",
      "|1985| 0.555804|\n",
      "|1984| 0.613839|\n",
      "|1983| 1.129464|\n",
      "|1982| 0.622768|\n",
      "|1981| 0.620536|\n",
      "|1980| 0.645089|\n",
      "+----+---------+\n",
      "only showing top 39 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "dfHigh = dfGroupYear.agg(max(\"High\"))\n",
    "dfHigh.orderBy(\"year\", ascending=False).show(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In quale hanno sono state scambiate più azioni di Apple?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|year|     Volume|\n",
      "+----+-----------+\n",
      "|2008|71495301500|\n",
      "|2007|61748996400|\n",
      "|2006|53924741500|\n",
      "|2005|45600245600|\n",
      "|2010|37756231800|\n",
      "|2009|35813421700|\n",
      "|1999|34275676400|\n",
      "|2012|32991051100|\n",
      "|2011|31014834900|\n",
      "|2004|30450417200|\n",
      "|2000|30075399200|\n",
      "|1998|28798548800|\n",
      "|2013|25605392400|\n",
      "|2001|23664449200|\n",
      "|2002|19253481800|\n",
      "|1995|18566634800|\n",
      "|1997|17990840000|\n",
      "|2003|17807563200|\n",
      "|2014|15914488100|\n",
      "|1987|14942827200|\n",
      "|1991|14336912800|\n",
      "|1994|14288974000|\n",
      "|1993|14113232000|\n",
      "|1986|13330805600|\n",
      "|1996|13298555200|\n",
      "|2015|13066049900|\n",
      "|1989|12726456400|\n",
      "|1985|11373068000|\n",
      "|1983|11128252800|\n",
      "|1990|11100485200|\n",
      "|1984|10494758400|\n",
      "|1988|10323244400|\n",
      "|1992|10284478400|\n",
      "|2016| 9682477800|\n",
      "|2018| 8539036200|\n",
      "|2017| 6810776500|\n",
      "|1982| 5341252000|\n",
      "|1981| 2049236000|\n",
      "|1980|  336212800|\n",
      "+----+-----------+\n",
      "only showing top 39 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "dfVolume = dfGroupYear.agg(sum(\"Volume\").alias(\"Volume\"))\n",
    "dfVolume.orderBy(\"Volume\", ascending=False).show(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il 29 giugno 2007 è stato rilasciato al pubblico il primo IPhone, come è variato il prezzo delle azioni di Apple nei 180 giorni successivi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-12-26\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = '2007-06-29'\n",
    "end_date = datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=180)\n",
    "end_date = datetime.strftime(end_date, '%Y-%m-%d') \n",
    "\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.date(2007, 6, 29), Open=17.424285888671875, High=17.714284896850586, Low=17.29857063293457, Close=17.43428611755371, Adj Close=15.272941589355469, Volume=284460400)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowFirst = df.filter(\"Date == '\"+start_date+\"'\").head()\n",
    "rowFirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': datetime.date(2007, 6, 29),\n",
       " 'Open': 17.424285888671875,\n",
       " 'High': 17.714284896850586,\n",
       " 'Low': 17.29857063293457,\n",
       " 'Close': 17.43428611755371,\n",
       " 'Adj Close': 15.272941589355469,\n",
       " 'Volume': 284460400}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictFirst = rowFirst.asDict()\n",
    "dictFirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': datetime.date(2007, 12, 26),\n",
       " 'Open': 28.43000030517578,\n",
       " 'High': 28.70857048034668,\n",
       " 'Low': 28.117143630981445,\n",
       " 'Close': 28.421428680419922,\n",
       " 'Adj Close': 24.89799690246582,\n",
       " 'Volume': 175933100}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowLast = df.filter(\"Date == '\"+end_date+\"'\").head()\n",
    "dictLast = rowLast.asDict()\n",
    "dictLast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
