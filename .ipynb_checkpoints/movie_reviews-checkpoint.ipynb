{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi di 28 milioni di recensioni di film\n",
    "# Procuriamoci il Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.grouplens.org/datasets/movielens/ml-latest.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inizializziamo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"movie_reviews\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importiamo il Dataset in un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|   _c0|    _c1|   _c2|       _c3|\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "|     1|   1590|   2.5|1256677236|\n",
      "|     1|   1591|   1.5|1256677475|\n",
      "|     1|   2134|   4.5|1256677464|\n",
      "|     1|   2478|   4.0|1256677239|\n",
      "|     1|   2840|   3.0|1256677500|\n",
      "|     1|   2986|   2.5|1256677496|\n",
      "|     1|   3020|   4.0|1256677260|\n",
      "|     1|   3424|   4.5|1256677444|\n",
      "|     1|   3698|   3.5|1256677243|\n",
      "|     1|   3826|   2.0|1256677210|\n",
      "|     1|   3893|   3.5|1256677486|\n",
      "|     2|    170|   3.5|1192913581|\n",
      "|     2|    849|   3.5|1192913537|\n",
      "|     2|   1186|   3.5|1192913611|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.load(\"ml-latest/ratings.csv\", format=\"csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "|     1|   1590|   2.5|1256677236|\n",
      "|     1|   1591|   1.5|1256677475|\n",
      "|     1|   2134|   4.5|1256677464|\n",
      "|     1|   2478|   4.0|1256677239|\n",
      "|     1|   2840|   3.0|1256677500|\n",
      "|     1|   2986|   2.5|1256677496|\n",
      "|     1|   3020|   4.0|1256677260|\n",
      "|     1|   3424|   4.5|1256677444|\n",
      "|     1|   3698|   3.5|1256677243|\n",
      "|     1|   3826|   2.0|1256677210|\n",
      "|     1|   3893|   3.5|1256677486|\n",
      "|     2|    170|   3.5|1192913581|\n",
      "|     2|    849|   3.5|1192913537|\n",
      "|     2|   1186|   3.5|1192913611|\n",
      "|     2|   1235|   3.0|1192913585|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"ml-latest/ratings.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correggiamo lo schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data_schema = [StructField('userID', StringType(), True),\n",
    "                StructField('movieID', StringType(), True),\n",
    "                StructField('rating', FloatType(), True),\n",
    "                StructField('timestamp', IntegerType(), True)]\n",
    "\n",
    "schema = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userID|movieID|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "|     1|   1590|   2.5|1256677236|\n",
      "|     1|   1591|   1.5|1256677475|\n",
      "|     1|   2134|   4.5|1256677464|\n",
      "|     1|   2478|   4.0|1256677239|\n",
      "|     1|   2840|   3.0|1256677500|\n",
      "|     1|   2986|   2.5|1256677496|\n",
      "|     1|   3020|   4.0|1256677260|\n",
      "|     1|   3424|   4.5|1256677444|\n",
      "|     1|   3698|   3.5|1256677243|\n",
      "|     1|   3826|   2.0|1256677210|\n",
      "|     1|   3893|   3.5|1256677486|\n",
      "|     2|    170|   3.5|1192913581|\n",
      "|     2|    849|   3.5|1192913537|\n",
      "|     2|   1186|   3.5|1192913611|\n",
      "|     2|   1235|   3.0|1192913585|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"false\") \\\n",
    "    .csv(\"ml-latest/ratings.csv\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userID: string (nullable = true)\n",
      " |-- movieID: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userID|movieID|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|2009-10-27|\n",
      "|     1|    481|   3.5|2009-10-27|\n",
      "|     1|   1091|   1.5|2009-10-27|\n",
      "|     1|   1257|   4.5|2009-10-27|\n",
      "|     1|   1449|   4.5|2009-10-27|\n",
      "|     1|   1590|   2.5|2009-10-27|\n",
      "|     1|   1591|   1.5|2009-10-27|\n",
      "|     1|   2134|   4.5|2009-10-27|\n",
      "|     1|   2478|   4.0|2009-10-27|\n",
      "|     1|   2840|   3.0|2009-10-27|\n",
      "|     1|   2986|   2.5|2009-10-27|\n",
      "|     1|   3020|   4.0|2009-10-27|\n",
      "|     1|   3424|   4.5|2009-10-27|\n",
      "|     1|   3698|   3.5|2009-10-27|\n",
      "|     1|   3826|   2.0|2009-10-27|\n",
      "|     1|   3893|   3.5|2009-10-27|\n",
      "|     2|    170|   3.5|2007-10-20|\n",
      "|     2|    849|   3.5|2007-10-20|\n",
      "|     2|   1186|   3.5|2007-10-20|\n",
      "|     2|   1235|   3.0|2007-10-20|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import  from_unixtime , to_date\n",
    "\n",
    "df.withColumn('timestamp', to_date(from_unixtime(df[\"timestamp\"]))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userID|movieID|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|    307|   3.5|2009-10-27 22:00:21|\n",
      "|     1|    481|   3.5|2009-10-27 22:04:16|\n",
      "|     1|   1091|   1.5|2009-10-27 22:04:31|\n",
      "|     1|   1257|   4.5|2009-10-27 22:04:20|\n",
      "|     1|   1449|   4.5|2009-10-27 22:01:04|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_utc_timestamp\n",
    "\n",
    "df = df.withColumn('timestamp', to_utc_timestamp(from_unixtime(df[\"timestamp\"]), \"yyyy-MM-dd hh:mm:ss\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userID: string (nullable = true)\n",
      " |-- movieID: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quante recensioni ci sono esattamente nel dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27753444\n"
     ]
    }
   ],
   "source": [
    "total_reviews = df.count()\n",
    "print(total_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è il numero di recensioni medie per utente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|reviewers_count|\n",
      "+---------------+\n",
      "|         283228|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "total_unique_reviewers = df.agg(countDistinct(\"userId\").alias(\"reviewers_count\"))\n",
    "total_unique_reviewers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283228\n"
     ]
    }
   ],
   "source": [
    "total_unique_reviewers = total_unique_reviewers.head()['reviewers_count']\n",
    "print(total_unique_reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.98976089934611\n"
     ]
    }
   ],
   "source": [
    "mean_reviews = total_reviews/total_unique_reviewers\n",
    "print(mean_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quale utente ha scritto più recensioni? Quante sono le recensioni che ha scritto? Qual è il voto medio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|count|\n",
      "+------+-----+\n",
      "|123100|23715|\n",
      "|117490| 9279|\n",
      "|134596| 8381|\n",
      "|212343| 7884|\n",
      "|242683| 7515|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"userID\").count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       avg(rating)|\n",
      "+------------------+\n",
      "|3.1306346194391734|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"userID=='123100'\").agg({\"rating\":\"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quali sono i film che hanno ricevuto più recensioni?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMovies = df.groupBy(\"movieID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieID|count|\n",
      "+-------+-----+\n",
      "|    318|97999|\n",
      "|    356|97040|\n",
      "|    296|92406|\n",
      "|    593|87899|\n",
      "|   2571|84545|\n",
      "|    260|81815|\n",
      "|    480|76451|\n",
      "|    527|71516|\n",
      "|    110|68803|\n",
      "|      1|68469|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovies.count().orderBy(\"count\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quali sono i 10 film con le recensioni più positive?\n",
    "# OPZIONE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+\n",
      "|movieID|        avg_rating|count_movieID|\n",
      "+-------+------------------+-------------+\n",
      "|    296| 4.173971387139363|        92406|\n",
      "|   1090|3.9017529880478086|        18825|\n",
      "|   2294|3.2357021735779252|        12974|\n",
      "|   3210| 3.636775639067115|         9819|\n",
      "|  48738| 3.849010703859877|         6166|\n",
      "+-------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMoviesAvg = dfMovies.agg({\"rating\":\"mean\", \"movieID\":\"count\"}) \\\n",
    "                    .withColumnRenamed(\"avg(rating)\", \"avg_rating\") \\\n",
    "                    .withColumnRenamed(\"count(movieId)\", \"count_movieID\") \n",
    "dfMoviesAvg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPZIONE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+\n",
      "|movieID|        avg_rating|count_rating|\n",
      "+-------+------------------+------------+\n",
      "|    296| 4.173971387139363|       92406|\n",
      "|   1090|3.9017529880478086|       18825|\n",
      "|   2294|3.2357021735779252|       12974|\n",
      "|   3210| 3.636775639067115|        9819|\n",
      "|  48738| 3.849010703859877|        6166|\n",
      "+-------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "dfMoviesAvg = dfMovies.agg(avg(\"rating\").alias(\"avg_rating\"), count(\"movieID\").alias(\"count_rating\"))\n",
    "dfMoviesAvg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMoviesMostRated = dfMoviesAvg.filter('count_rating >= 100')\n",
    "dfMoviesMostRated.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+\n",
      "|movieID|        avg_rating|count_rating|\n",
      "+-------+------------------+------------+\n",
      "| 171011|4.4865181711606095|         853|\n",
      "| 159817| 4.458092485549133|        1384|\n",
      "|    318| 4.424188001918387|       97999|\n",
      "| 170705| 4.399898373983739|         984|\n",
      "| 174053| 4.350558659217877|        1074|\n",
      "| 171495| 4.343949044585988|         157|\n",
      "| 172591| 4.339667458432304|         421|\n",
      "|    858| 4.332892749244713|       60904|\n",
      "|     50| 4.291958829205532|       62180|\n",
      "| 176601| 4.263888888888889|         180|\n",
      "|   1221|4.2630353697749195|       38875|\n",
      "| 172577| 4.261904761904762|         126|\n",
      "|    527| 4.257501817775044|       71516|\n",
      "|   2019|4.2541157909178215|       14578|\n",
      "| 163809| 4.244031830238727|         377|\n",
      "| 185135|  4.23943661971831|         213|\n",
      "|   1203| 4.237075455914338|       17931|\n",
      "| 179135| 4.236389684813753|         349|\n",
      "|    904| 4.230798598634567|       22264|\n",
      "|   2959| 4.230663235786717|       65678|\n",
      "+-------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMoviesTopRated = dfMoviesMostRated.orderBy(\"avg_rating\", ascending=False)\n",
    "dfMoviesTopRated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quali sono i 10 film con le recensioni più negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+\n",
      "|movieID|        avg_rating|count_rating|\n",
      "+-------+------------------+------------+\n",
      "|   8859|0.8739495798319328|         238|\n",
      "|   6483|1.0138592750533049|         469|\n",
      "|   4775| 1.141025641025641|         741|\n",
      "|   1826|1.2038288288288288|         444|\n",
      "|   6587|1.2055555555555555|         810|\n",
      "|  31698|1.2441176470588236|         680|\n",
      "|   5739|1.2612359550561798|         178|\n",
      "|  61348|1.2672849915682969|         593|\n",
      "|   5738|1.3549382716049383|         162|\n",
      "|   3574|1.3580645161290323|         155|\n",
      "|   6872|1.3608445297504799|         521|\n",
      "|   5740| 1.371212121212121|         132|\n",
      "|   6371| 1.378238341968912|         386|\n",
      "|   5737|1.3897849462365592|         186|\n",
      "|  54290|1.4051724137931034|         232|\n",
      "|   1495|1.4207792207792207|         770|\n",
      "|   1990|1.4588235294117646|         170|\n",
      "|   5647|1.4662447257383966|         237|\n",
      "|   5736|1.4705882352941178|         204|\n",
      "|  50798|1.4722872755659642|        1281|\n",
      "+-------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMoviesTopRated = dfMoviesMostRated.orderBy(\"avg_rating\")\n",
    "dfMoviesTopRated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quali sono le 10 recensioni più recenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userID|movieID|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "| 82922| 167780|   4.0|2018-09-26 08:59:09|\n",
      "| 82922|  53519|   4.0|2018-09-26 08:58:50|\n",
      "|280481|    494|   3.0|2018-09-26 08:58:47|\n",
      "|280481|   2355|   3.0|2018-09-26 08:58:43|\n",
      "|280481|   2294|   2.0|2018-09-26 08:58:41|\n",
      "|280481| 176101|   3.5|2018-09-26 08:58:30|\n",
      "|280481|  64614|   3.0|2018-09-26 08:58:22|\n",
      "| 82922| 165831|   4.0|2018-09-26 08:58:09|\n",
      "|280481|   1079|   2.5|2018-09-26 08:58:06|\n",
      "| 82922|  52281|   4.0|2018-09-26 08:58:05|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"timestamp\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è il film più visto per anno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----+\n",
      "|userID|movieID|rating|year|\n",
      "+------+-------+------+----+\n",
      "|     1|    307|   3.5|2009|\n",
      "|     1|    481|   3.5|2009|\n",
      "|     1|   1091|   1.5|2009|\n",
      "|     1|   1257|   4.5|2009|\n",
      "|     1|   1449|   4.5|2009|\n",
      "+------+-------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "dfWithYear = df.withColumn(\"year\", year(df[\"timestamp\"]))\n",
    "dfWithYear = dfWithYear.drop(\"timestamp\")\n",
    "dfWithYear.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------------+\n",
      "|year|movieID|count_rating|\n",
      "+----+-------+------------+\n",
      "|2005|    255|          43|\n",
      "|2005|   1917|        3460|\n",
      "|2005|   3793|        4089|\n",
      "|2005|   5064|         788|\n",
      "|2005|   6966|         257|\n",
      "+----+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovieYear = dfWithYear.groupBy(\"year\", \"movieID\").agg(count(\"rating\").alias(\"count_rating\"))\n",
    "dfMovieYear.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|count_rating|\n",
      "+----+------------+\n",
      "|1996|       25760|\n",
      "|2015|       12775|\n",
      "|1997|       11350|\n",
      "|2016|        8976|\n",
      "|2017|        7874|\n",
      "|2000|        7453|\n",
      "|2005|        6230|\n",
      "|1999|        4621|\n",
      "|2001|        4516|\n",
      "|2018|        4311|\n",
      "|2008|        4208|\n",
      "|2006|        4000|\n",
      "|2010|        3884|\n",
      "|2009|        3720|\n",
      "|2004|        3699|\n",
      "|2003|        3684|\n",
      "|2002|        3553|\n",
      "|2007|        3409|\n",
      "|2011|        3282|\n",
      "|2013|        2713|\n",
      "|2014|        2673|\n",
      "|2012|        2422|\n",
      "|1998|        2398|\n",
      "|1995|           1|\n",
      "+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "dfMostRatedYear = dfMovieYear.groupBy(\"year\") \\\n",
    "            .agg(max(\"count_rating\") \\\n",
    "            .alias(\"count_rating\")) \\\n",
    "            .orderBy(\"count_rating\", ascending=False)\n",
    "\n",
    "dfMostRatedYear.show(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------------+\n",
      "|year|movieID|count_rating|\n",
      "+----+-------+------------+\n",
      "|2003|   5952|        3684|\n",
      "|2007|   2571|        3409|\n",
      "|2018|    318|        4311|\n",
      "|2015|   2571|       12775|\n",
      "|2006|   7153|        4000|\n",
      "|2013|    318|        2713|\n",
      "|1997|    780|       11350|\n",
      "|2014|    318|        2673|\n",
      "|2004|   7153|        3699|\n",
      "|1996|    592|       25760|\n",
      "|1998|   1721|        2398|\n",
      "|2012|  79132|        2422|\n",
      "|2009|  58559|        3720|\n",
      "|2016|    318|        8976|\n",
      "|1995|     47|           1|\n",
      "|1995|     21|           1|\n",
      "|1995|   1176|           1|\n",
      "|1995|   1079|           1|\n",
      "|2001|   1210|        4516|\n",
      "|2005|   5952|        6230|\n",
      "|2000|   1210|        7453|\n",
      "|2010|  72998|        3884|\n",
      "|2011|  79132|        3282|\n",
      "|2008|   2571|        4208|\n",
      "|2017|    318|        7874|\n",
      "|1999|   2396|        4621|\n",
      "|2002|   4993|        3553|\n",
      "+----+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import max, col\n",
    "\n",
    "window = Window.partitionBy(\"year\")\n",
    "\n",
    "dfMostRatedYear = dfMovieYear.withColumn(\"max\", max(\"count_rating\").over(window)) \\\n",
    "                            .where(col(\"count_rating\")==col(\"max\")).drop(\"max\")\n",
    "\n",
    "dfMostRatedYear.show(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------------+\n",
      "|year|movieID|count_rating|\n",
      "+----+-------+------------+\n",
      "|2018|    318|        4311|\n",
      "|2017|    318|        7874|\n",
      "|2016|    318|        8976|\n",
      "|2015|   2571|       12775|\n",
      "|2014|    318|        2673|\n",
      "|2013|    318|        2713|\n",
      "|2012|  79132|        2422|\n",
      "|2011|  79132|        3282|\n",
      "|2010|  72998|        3884|\n",
      "|2009|  58559|        3720|\n",
      "|2008|   2571|        4208|\n",
      "|2007|   2571|        3409|\n",
      "|2006|   7153|        4000|\n",
      "|2005|   5952|        6230|\n",
      "|2004|   7153|        3699|\n",
      "|2003|   5952|        3684|\n",
      "|2002|   4993|        3553|\n",
      "|2001|   1210|        4516|\n",
      "|2000|   1210|        7453|\n",
      "|1999|   2396|        4621|\n",
      "|1998|   1721|        2398|\n",
      "|1997|    780|       11350|\n",
      "|1996|    592|       25760|\n",
      "|1995|     47|           1|\n",
      "|1995|     21|           1|\n",
      "|1995|   1176|           1|\n",
      "|1995|   1079|           1|\n",
      "+----+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMostRatedYear = dfMostRatedYear.orderBy(\"year\", ascending=False)\n",
    "dfMostRatedYear.show(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMostRatedYear = dfMostRatedYear.where(\"year != 1995\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMostViewedYear = dfMostRatedYear.withColumn(\"total_viewers\",dfMostRatedYear[\"count_rating\"]*100) \\\n",
    "                        .drop(\"count_rating\")\n",
    "dfMostViewedYear.show(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiungere titolo e genere e alla lista dei film per anno e scrivere un file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = spark.read.csv(\"ml-latest/movies.csv\", header=True, inferSchema=True)\n",
    "df_desc.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------------+---------------------------------------------------------+-----------------------------------------------+---------------------------------------------------------+-----------------------------------------------+---------------------------------------------------------+-----------------------------------------------+\n",
      "|movieID|year|total_viewers|title                                                    |genres                                         |title                                                    |genres                                         |title                                                    |genres                                         |\n",
      "+-------+----+-------------+---------------------------------------------------------+-----------------------------------------------+---------------------------------------------------------+-----------------------------------------------+---------------------------------------------------------+-----------------------------------------------+\n",
      "|318    |2018|431100       |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |\n",
      "|318    |2017|787400       |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |\n",
      "|318    |2016|897600       |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |\n",
      "|2571   |2015|1277500      |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |\n",
      "|318    |2014|267300       |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |\n",
      "|318    |2013|271300       |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |Shawshank Redemption, The (1994)                         |Crime|Drama                                    |\n",
      "|79132  |2012|242200       |Inception (2010)                                         |Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX|Inception (2010)                                         |Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX|Inception (2010)                                         |Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX|\n",
      "|79132  |2011|328200       |Inception (2010)                                         |Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX|Inception (2010)                                         |Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX|Inception (2010)                                         |Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX|\n",
      "|72998  |2010|388400       |Avatar (2009)                                            |Action|Adventure|Sci-Fi|IMAX                   |Avatar (2009)                                            |Action|Adventure|Sci-Fi|IMAX                   |Avatar (2009)                                            |Action|Adventure|Sci-Fi|IMAX                   |\n",
      "|58559  |2009|372000       |Dark Knight, The (2008)                                  |Action|Crime|Drama|IMAX                        |Dark Knight, The (2008)                                  |Action|Crime|Drama|IMAX                        |Dark Knight, The (2008)                                  |Action|Crime|Drama|IMAX                        |\n",
      "|2571   |2008|420800       |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |\n",
      "|2571   |2007|340900       |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |Matrix, The (1999)                                       |Action|Sci-Fi|Thriller                         |\n",
      "|7153   |2006|400000       |Lord of the Rings: The Return of the King, The (2003)    |Action|Adventure|Drama|Fantasy                 |Lord of the Rings: The Return of the King, The (2003)    |Action|Adventure|Drama|Fantasy                 |Lord of the Rings: The Return of the King, The (2003)    |Action|Adventure|Drama|Fantasy                 |\n",
      "|5952   |2005|623000       |Lord of the Rings: The Two Towers, The (2002)            |Adventure|Fantasy                              |Lord of the Rings: The Two Towers, The (2002)            |Adventure|Fantasy                              |Lord of the Rings: The Two Towers, The (2002)            |Adventure|Fantasy                              |\n",
      "|7153   |2004|369900       |Lord of the Rings: The Return of the King, The (2003)    |Action|Adventure|Drama|Fantasy                 |Lord of the Rings: The Return of the King, The (2003)    |Action|Adventure|Drama|Fantasy                 |Lord of the Rings: The Return of the King, The (2003)    |Action|Adventure|Drama|Fantasy                 |\n",
      "|5952   |2003|368400       |Lord of the Rings: The Two Towers, The (2002)            |Adventure|Fantasy                              |Lord of the Rings: The Two Towers, The (2002)            |Adventure|Fantasy                              |Lord of the Rings: The Two Towers, The (2002)            |Adventure|Fantasy                              |\n",
      "|4993   |2002|355300       |Lord of the Rings: The Fellowship of the Ring, The (2001)|Adventure|Fantasy                              |Lord of the Rings: The Fellowship of the Ring, The (2001)|Adventure|Fantasy                              |Lord of the Rings: The Fellowship of the Ring, The (2001)|Adventure|Fantasy                              |\n",
      "|1210   |2001|451600       |Star Wars: Episode VI - Return of the Jedi (1983)        |Action|Adventure|Sci-Fi                        |Star Wars: Episode VI - Return of the Jedi (1983)        |Action|Adventure|Sci-Fi                        |Star Wars: Episode VI - Return of the Jedi (1983)        |Action|Adventure|Sci-Fi                        |\n",
      "|1210   |2000|745300       |Star Wars: Episode VI - Return of the Jedi (1983)        |Action|Adventure|Sci-Fi                        |Star Wars: Episode VI - Return of the Jedi (1983)        |Action|Adventure|Sci-Fi                        |Star Wars: Episode VI - Return of the Jedi (1983)        |Action|Adventure|Sci-Fi                        |\n",
      "|2396   |1999|462100       |Shakespeare in Love (1998)                               |Comedy|Drama|Romance                           |Shakespeare in Love (1998)                               |Comedy|Drama|Romance                           |Shakespeare in Love (1998)                               |Comedy|Drama|Romance                           |\n",
      "|1721   |1998|239800       |Titanic (1997)                                           |Drama|Romance                                  |Titanic (1997)                                           |Drama|Romance                                  |Titanic (1997)                                           |Drama|Romance                                  |\n",
      "|780    |1997|1135000      |Independence Day (a.k.a. ID4) (1996)                     |Action|Adventure|Sci-Fi|Thriller               |Independence Day (a.k.a. ID4) (1996)                     |Action|Adventure|Sci-Fi|Thriller               |Independence Day (a.k.a. ID4) (1996)                     |Action|Adventure|Sci-Fi|Thriller               |\n",
      "|592    |1996|2576000      |Batman (1989)                                            |Action|Crime|Thriller                          |Batman (1989)                                            |Action|Crime|Thriller                          |Batman (1989)                                            |Action|Crime|Thriller                          |\n",
      "+-------+----+-------------+---------------------------------------------------------+-----------------------------------------------+---------------------------------------------------------+-----------------------------------------------+---------------------------------------------------------+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMostViewedYear = dfMostViewedYear.join(df_desc, [\"movieId\"])\n",
    "\n",
    "# impostando il secondo parametro del metodo .show() a False\n",
    "# possiamo visualizzare tutto il Dataframe in ampiezza\n",
    "\n",
    "dfMostViewedYear.show(27, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Found duplicate column(s) when inserting into file:/home/sparkmachine/Notebook/top_movie_by_year: `genres`, `title`;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o314.csv.\n: org.apache.spark.sql.AnalysisException: Found duplicate column(s) when inserting into file:/home/sparkmachine/Notebook/top_movie_by_year: `genres`, `title`;\n\tat org.apache.spark.sql.util.SchemaUtils$.checkColumnNameDuplication(SchemaUtils.scala:85)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:65)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:664)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-7db708c6f210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfMostViewedYear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"top_movie_by_year\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue)\u001b[0m\n\u001b[1;32m    930\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                        encoding=encoding, emptyValue=emptyValue)\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Found duplicate column(s) when inserting into file:/home/sparkmachine/Notebook/top_movie_by_year: `genres`, `title`;'"
     ]
    }
   ],
   "source": [
    "dfMostViewedYear.write.csv(\"top_movie_by_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
