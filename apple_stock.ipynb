{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi del prezzo delle azioni di Apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inizializziamo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AppleStock\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importiamo il Dataset all'interno di un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|               Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|1980-12-12 00:00:00|0.513393|0.515625|0.513393|0.513393| 0.410525|117258400|\n",
      "|1980-12-15 00:00:00|0.488839|0.488839|0.486607|0.486607| 0.389106| 43971200|\n",
      "|1980-12-16 00:00:00|0.453125|0.453125|0.450893|0.450893| 0.360548| 26432000|\n",
      "|1980-12-17 00:00:00|0.462054|0.464286|0.462054|0.462054| 0.369472| 21610400|\n",
      "|1980-12-18 00:00:00|0.475446|0.477679|0.475446|0.475446| 0.380182| 18362400|\n",
      "|1980-12-19 00:00:00|0.504464|0.506696|0.504464|0.504464| 0.403385| 12157600|\n",
      "|1980-12-22 00:00:00|0.529018|0.531250|0.529018|0.529018| 0.423019|  9340800|\n",
      "|1980-12-23 00:00:00|0.551339|0.553571|0.551339|0.551339| 0.440868| 11737600|\n",
      "|1980-12-24 00:00:00|0.580357|0.582589|0.580357|0.580357| 0.464072| 12000800|\n",
      "|1980-12-26 00:00:00|0.633929|0.636161|0.633929|0.633929| 0.506909| 13893600|\n",
      "|1980-12-29 00:00:00|0.642857|0.645089|0.642857|0.642857| 0.514049| 23290400|\n",
      "|1980-12-30 00:00:00|0.629464|0.629464|0.627232|0.627232| 0.501554| 17220000|\n",
      "|1980-12-31 00:00:00|0.611607|0.611607|0.609375|0.609375| 0.487276|  8937600|\n",
      "|1981-01-02 00:00:00|0.616071|0.620536|0.616071|0.616071| 0.492630|  5415200|\n",
      "|1981-01-05 00:00:00|0.604911|0.604911|0.602679|0.602679| 0.481921|  8932000|\n",
      "|1981-01-06 00:00:00|0.578125|0.578125|0.575893|0.575893| 0.460502| 11289600|\n",
      "|1981-01-07 00:00:00|0.553571|0.553571|0.551339|0.551339| 0.440868| 13921600|\n",
      "|1981-01-08 00:00:00|0.542411|0.542411|0.540179|0.540179| 0.431944|  9956800|\n",
      "|1981-01-09 00:00:00|0.569196|0.571429|0.569196|0.569196| 0.455147|  5376000|\n",
      "|1981-01-12 00:00:00|0.569196|0.569196|0.564732|0.564732| 0.451577|  5924800|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/AAPL.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correggiamo lo schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|               Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "|1980-12-12 00:00:00|0.513393|0.515625|0.513393|0.513393| 0.410525|117258400|\n",
      "|1980-12-15 00:00:00|0.488839|0.488839|0.486607|0.486607| 0.389106| 43971200|\n",
      "|1980-12-16 00:00:00|0.453125|0.453125|0.450893|0.450893| 0.360548| 26432000|\n",
      "|1980-12-17 00:00:00|0.462054|0.464286|0.462054|0.462054| 0.369472| 21610400|\n",
      "|1980-12-18 00:00:00|0.475446|0.477679|0.475446|0.475446| 0.380182| 18362400|\n",
      "|1980-12-19 00:00:00|0.504464|0.506696|0.504464|0.504464| 0.403385| 12157600|\n",
      "|1980-12-22 00:00:00|0.529018| 0.53125|0.529018|0.529018| 0.423019|  9340800|\n",
      "|1980-12-23 00:00:00|0.551339|0.553571|0.551339|0.551339| 0.440868| 11737600|\n",
      "|1980-12-24 00:00:00|0.580357|0.582589|0.580357|0.580357| 0.464072| 12000800|\n",
      "|1980-12-26 00:00:00|0.633929|0.636161|0.633929|0.633929| 0.506909| 13893600|\n",
      "|1980-12-29 00:00:00|0.642857|0.645089|0.642857|0.642857| 0.514049| 23290400|\n",
      "|1980-12-30 00:00:00|0.629464|0.629464|0.627232|0.627232| 0.501554| 17220000|\n",
      "|1980-12-31 00:00:00|0.611607|0.611607|0.609375|0.609375| 0.487276|  8937600|\n",
      "|1981-01-02 00:00:00|0.616071|0.620536|0.616071|0.616071|  0.49263|  5415200|\n",
      "|1981-01-05 00:00:00|0.604911|0.604911|0.602679|0.602679| 0.481921|  8932000|\n",
      "|1981-01-06 00:00:00|0.578125|0.578125|0.575893|0.575893| 0.460502| 11289600|\n",
      "|1981-01-07 00:00:00|0.553571|0.553571|0.551339|0.551339| 0.440868| 13921600|\n",
      "|1981-01-08 00:00:00|0.542411|0.542411|0.540179|0.540179| 0.431944|  9956800|\n",
      "|1981-01-09 00:00:00|0.569196|0.571429|0.569196|0.569196| 0.455147|  5376000|\n",
      "|1981-01-12 00:00:00|0.569196|0.569196|0.564732|0.564732| 0.451577|  5924800|\n",
      "+-------------------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data_schema = [ StructField('Date', TimestampType(), True),\n",
    "                StructField('Open', FloatType(), True),\n",
    "                StructField('High', FloatType(), True),\n",
    "                StructField('Low', FloatType(), True),\n",
    "                StructField('Close', FloatType(), True),\n",
    "                StructField('Adj Close', FloatType(), True),\n",
    "                StructField('Volume', IntegerType(), True),]\n",
    "            \n",
    "schema = StructType(fields=data_schema)\n",
    "\n",
    "df = spark.read.schema(schema).option(\"header\",\"true\").option(\"inferSchema\",\"false\") \\\n",
    "                    .csv(\"data/AAPL.csv\")\n",
    "\n",
    "df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertiamo il timestamp in una data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|      Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|1980-12-12|0.513393|0.515625|0.513393|0.513393| 0.410525|117258400|\n",
      "|1980-12-15|0.488839|0.488839|0.486607|0.486607| 0.389106| 43971200|\n",
      "|1980-12-16|0.453125|0.453125|0.450893|0.450893| 0.360548| 26432000|\n",
      "|1980-12-17|0.462054|0.464286|0.462054|0.462054| 0.369472| 21610400|\n",
      "|1980-12-18|0.475446|0.477679|0.475446|0.475446| 0.380182| 18362400|\n",
      "|1980-12-19|0.504464|0.506696|0.504464|0.504464| 0.403385| 12157600|\n",
      "|1980-12-22|0.529018| 0.53125|0.529018|0.529018| 0.423019|  9340800|\n",
      "|1980-12-23|0.551339|0.553571|0.551339|0.551339| 0.440868| 11737600|\n",
      "|1980-12-24|0.580357|0.582589|0.580357|0.580357| 0.464072| 12000800|\n",
      "|1980-12-26|0.633929|0.636161|0.633929|0.633929| 0.506909| 13893600|\n",
      "|1980-12-29|0.642857|0.645089|0.642857|0.642857| 0.514049| 23290400|\n",
      "|1980-12-30|0.629464|0.629464|0.627232|0.627232| 0.501554| 17220000|\n",
      "|1980-12-31|0.611607|0.611607|0.609375|0.609375| 0.487276|  8937600|\n",
      "|1981-01-02|0.616071|0.620536|0.616071|0.616071|  0.49263|  5415200|\n",
      "|1981-01-05|0.604911|0.604911|0.602679|0.602679| 0.481921|  8932000|\n",
      "|1981-01-06|0.578125|0.578125|0.575893|0.575893| 0.460502| 11289600|\n",
      "|1981-01-07|0.553571|0.553571|0.551339|0.551339| 0.440868| 13921600|\n",
      "|1981-01-08|0.542411|0.542411|0.540179|0.540179| 0.431944|  9956800|\n",
      "|1981-01-09|0.569196|0.571429|0.569196|0.569196| 0.455147|  5376000|\n",
      "|1981-01-12|0.569196|0.569196|0.564732|0.564732| 0.451577|  5924800|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df = df.withColumn('Date', to_date(df[\"Date\"], \"yyyy-MM-dd\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è stato il valore massimo raggiunto dal AAPL? In che data lo ha raggiunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+---------+--------+\n",
      "|      Date|  Open|  High|   Low| Close|Adj Close|  Volume|\n",
      "+----------+------+------+------+------+---------+--------+\n",
      "|2018-10-03|230.05|233.47|229.78|232.07|229.39209|28654800|\n",
      "|2018-10-04|230.78|232.35|226.73|227.99|225.35918|32042000|\n",
      "|2018-10-02|227.25| 230.0|226.63|229.28| 226.6343|24788200|\n",
      "|2018-09-05|228.99|229.67| 225.1|226.87|224.25209|33333000|\n",
      "|2018-10-01|227.95|229.42|226.35|227.26| 224.6376|23600800|\n",
      "|2018-09-04|228.41|229.18|226.63|228.36| 225.7249|27390100|\n",
      "|2018-08-31|226.51|228.87| 226.0|227.63|225.00334|43340100|\n",
      "|2018-10-05|227.96|228.41|220.58|224.29|221.70186|33580500|\n",
      "|2018-09-13|223.52|228.35|222.57|226.41|223.79741|41706400|\n",
      "|2018-08-30|223.25|228.26| 222.4|225.03|222.43332|48793800|\n",
      "+----------+------+------+------+------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"High\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual è stato il valore massimo raggiunto dal AAPL dopo il 2000? In che data lo ha raggiunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|      Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|2003-04-17|0.942857|0.946429|0.908571|0.937143| 0.820964|154064400|\n",
      "|2003-04-16|0.927857|0.976429|0.922857|0.945714| 0.828473|254044000|\n",
      "|2003-04-11|1.003571|1.031429|0.923571|0.942857|  0.82597|348177200|\n",
      "|2003-04-21|0.937857|0.942143|0.927143|0.938571| 0.822216| 38080000|\n",
      "|2003-04-24|0.965714|0.972143|0.928571|    0.96| 0.840988| 81277000|\n",
      "|2003-04-22|0.941429|0.972857|   0.935|   0.965| 0.845368| 75142200|\n",
      "|2003-04-25|0.961429|    0.97|   0.945|0.953571| 0.835356| 51329600|\n",
      "|2003-04-15|0.970714|0.971429|    0.95|0.956429| 0.837859| 75992000|\n",
      "|2002-10-08|0.992857|0.997143|0.954286|0.977143| 0.856006|113411200|\n",
      "|2003-04-23|0.966429|0.973571|0.954286|    0.97| 0.849748| 52420200|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Date >= '2000-01-01'\").orderBy(\"Low\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
